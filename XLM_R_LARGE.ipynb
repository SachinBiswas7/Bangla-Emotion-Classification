{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNaFuZUrg6veWRtAb7sPI2F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SachinBiswas7/Bangla-Emotion-Classification/blob/main/XLM_R_LARGE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9HNjVUgxZ-Q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Dataset.csv\")"
      ],
      "metadata": {
        "id": "QSEZoxex1hkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "JXk61zKI1mSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Emotion\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "df.groupby('Emotion').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "metadata": {
        "id": "3vsx077k1ovP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#label encoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df['Emotion_label'] = le.fit_transform(df['Emotion'])\n"
      ],
      "metadata": {
        "id": "9anJo3Tf1u-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop Racial biases\n",
        "df.drop(['Racial Biases'], axis=1, inplace=True)\n",
        "#drop Hatred Percentage\n",
        "df.drop(['Hatred Percentage',], axis=1, inplace=True)\n",
        "#drop Depression Percentage\n",
        "df.drop(['Depression Percentage'], axis=1, inplace=True)\n",
        "#drop year\n",
        "df.drop(['Year'], axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "muKM9bn610vG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data preprocessing using spacy\n",
        "\n",
        "#removing unnecessary punctuation\n",
        "import re\n",
        "\n",
        "# Data cleaning function\n",
        "def process_comments(Comment):\n",
        "    Comment = re.sub('[^\\u0980-\\u09FF]',' ',str(Comment)) #removing unnecessary punctuation\n",
        "    return Comment\n",
        "\n",
        "df['Cleaned'] = df['Text'].apply(process_comments)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "CrQLyUHqSuUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load Bengali stop words from a CSV file\n",
        "stop_words_df = pd.read_csv('stopwords_bangla.csv')  # Assuming the CSV has one column with stop words\n",
        "stop_words_df=stop_words_df.drop(['Unnamed: 0'], axis=1)\n",
        "# Convert the stop words to a list\n",
        "stop_words_list = stop_words_df.iloc[:, 0].tolist()  # Convert the column to a list\n",
        "\n",
        "# Check the stop words list\n",
        "print(\"Stop words list:\", stop_words_list[:10])  # Print first 10 stop words for verification\n",
        "\n",
        "\n",
        "# Function to remove stop words\n",
        "def remove_stop_words(text, stop_words):\n",
        "    if isinstance(text, str):  # Ensure the text is a string\n",
        "        # Tokenize text (simple split for Bengali)\n",
        "        words = text.split()\n",
        "        # Filter out stop words\n",
        "        filtered_words = [word for word in words if word not in stop_words]\n",
        "        # Join words back into a single string\n",
        "        return ' '.join(filtered_words)\n",
        "    else:\n",
        "        return text  # If text is not a string, return it as is\n",
        "\n",
        "# Assuming 'df' is the DataFrame and 'Cleaned' is the column with text data\n",
        "# Check a few entries in the original DataFrame\n",
        "print(\"Original texts:\", df['Cleaned'].head())\n",
        "\n",
        "# Apply the function to the DataFrame\n",
        "df['filtered_text'] = df['Cleaned'].apply(lambda x: remove_stop_words(x, stop_words_list))\n",
        "\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "2Y0aMtIu2KIX",
        "outputId": "50171192-32c0-402b-fbfe-a995ec4fa985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop words list: ['অই', 'অগত্যা', 'অত: পর', 'অতএব', 'অথচ', 'অথবা', 'অধিক', 'অধীনে', 'অধ্যায়', 'অনুগ্রহ']\n",
            "Original texts: 0    নির্বাচনের আগের রাতে সুষ্টু শান্তিপূর্ণ ভাবে ভ...\n",
            "1    জনগণ মনের আনন্দে নিজেদের ভোট কাস্ট করে দেশদ্রো...\n",
            "2                                     ভেজাল নির্বাচন  \n",
            "3    বিএনপি ও রাজাকার সমর্থকরা হেরে গেলে দেশের জন্য...\n",
            "4    সূক্ষ্ম কারচুপি বলে এতদিন একটা কথার কথা ছিল  এ...\n",
            "Name: Cleaned, dtype: object\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SL  Emotion                                               Text  \\\n",
              "0   1  disgust  নির্বাচনের আগের রাতে সুষ্টু শান্তিপূর্ণ ভাবে ভ...   \n",
              "1   2  disgust  জনগণ মনের আনন্দে নিজেদের ভোট কাস্ট করে দেশদ্রো...   \n",
              "2   3    angry                                   ভেজাল নির্বাচন ।   \n",
              "3   4    happy  বিএনপি ও রাজাকার সমর্থকরা হেরে গেলে দেশের জন্য...   \n",
              "4   5    angry  সূক্ষ্ম কারচুপি বলে এতদিন একটা কথার কথা ছিল, এ...   \n",
              "\n",
              "   Emotion_label                                            Cleaned  \\\n",
              "0              1  নির্বাচনের আগের রাতে সুষ্টু শান্তিপূর্ণ ভাবে ভ...   \n",
              "1              1  জনগণ মনের আনন্দে নিজেদের ভোট কাস্ট করে দেশদ্রো...   \n",
              "2              0                                   ভেজাল নির্বাচন     \n",
              "3              3  বিএনপি ও রাজাকার সমর্থকরা হেরে গেলে দেশের জন্য...   \n",
              "4              0  সূক্ষ্ম কারচুপি বলে এতদিন একটা কথার কথা ছিল  এ...   \n",
              "\n",
              "                                       filtered_text  \n",
              "0  নির্বাচনের আগের রাতে সুষ্টু শান্তিপূর্ণ ভোট ব...  \n",
              "1  জনগণ মনের আনন্দে ভোট কাস্ট দেশদ্রোহী পেট্রল বো...  \n",
              "2                                     ভেজাল নির্বাচন  \n",
              "3  বিএনপি রাজাকার সমর্থকরা হেরে দেশের আমিও সন্তুষ...  \n",
              "4  সূক্ষ্ম কারচুপি এতদিন একটা কথার কথা বাস্তব রূপ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3db8d990-9825-4e1b-afec-06d5f9308f7f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SL</th>\n",
              "      <th>Emotion</th>\n",
              "      <th>Text</th>\n",
              "      <th>Emotion_label</th>\n",
              "      <th>Cleaned</th>\n",
              "      <th>filtered_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>disgust</td>\n",
              "      <td>নির্বাচনের আগের রাতে সুষ্টু শান্তিপূর্ণ ভাবে ভ...</td>\n",
              "      <td>1</td>\n",
              "      <td>নির্বাচনের আগের রাতে সুষ্টু শান্তিপূর্ণ ভাবে ভ...</td>\n",
              "      <td>নির্বাচনের আগের রাতে সুষ্টু শান্তিপূর্ণ ভোট ব...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>disgust</td>\n",
              "      <td>জনগণ মনের আনন্দে নিজেদের ভোট কাস্ট করে দেশদ্রো...</td>\n",
              "      <td>1</td>\n",
              "      <td>জনগণ মনের আনন্দে নিজেদের ভোট কাস্ট করে দেশদ্রো...</td>\n",
              "      <td>জনগণ মনের আনন্দে ভোট কাস্ট দেশদ্রোহী পেট্রল বো...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>angry</td>\n",
              "      <td>ভেজাল নির্বাচন ।</td>\n",
              "      <td>0</td>\n",
              "      <td>ভেজাল নির্বাচন</td>\n",
              "      <td>ভেজাল নির্বাচন</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>happy</td>\n",
              "      <td>বিএনপি ও রাজাকার সমর্থকরা হেরে গেলে দেশের জন্য...</td>\n",
              "      <td>3</td>\n",
              "      <td>বিএনপি ও রাজাকার সমর্থকরা হেরে গেলে দেশের জন্য...</td>\n",
              "      <td>বিএনপি রাজাকার সমর্থকরা হেরে দেশের আমিও সন্তুষ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>angry</td>\n",
              "      <td>সূক্ষ্ম কারচুপি বলে এতদিন একটা কথার কথা ছিল, এ...</td>\n",
              "      <td>0</td>\n",
              "      <td>সূক্ষ্ম কারচুপি বলে এতদিন একটা কথার কথা ছিল  এ...</td>\n",
              "      <td>সূক্ষ্ম কারচুপি এতদিন একটা কথার কথা বাস্তব রূপ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3db8d990-9825-4e1b-afec-06d5f9308f7f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3db8d990-9825-4e1b-afec-06d5f9308f7f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3db8d990-9825-4e1b-afec-06d5f9308f7f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-df9c0e3a-780e-4305-8012-a0e34a8282be\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df9c0e3a-780e-4305-8012-a0e34a8282be')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-df9c0e3a-780e-4305-8012-a0e34a8282be button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 36000,\n  \"fields\": [\n    {\n      \"column\": \"SL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10392,\n        \"min\": 1,\n        \"max\": 36000,\n        \"num_unique_values\": 36000,\n        \"samples\": [\n          16462,\n          23580,\n          23641\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Emotion\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"disgust\",\n          \"angry\",\n          \"sad\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11270,\n        \"samples\": [\n          \"\\u098f\\u099f\\u09be \\u0986\\u09ae\\u09c7\\u09b0\\u09bf\\u0995\\u09be\\u09b0 \\u098f\\u0995\\u099f\\u09be \\u09ac\\u09dc\\u09a7\\u09b0\\u09a8\\u09c7\\u09b0 \\u099a\\u09be\\u09b2! \\u099c\\u09be\\u09a4\\u09c0\\u09df \\u09aa\\u09b0\\u09bf\\u099a\\u09df \\u09aa\\u098f\\u09c7\\u09b0 \\u0995\\u09bf \\u0995\\u09c7\\u09be\\u09a8 \\u09ad\\u09c7\\u09b2\\u09c1 \\u09b8\\u09b0\\u0995\\u09be\\u09b0 \\u09a6\\u09bf\\u09a4\\u09c7 \\u099a\\u09be\\u09df \\u09a8\\u09be ?\\u09a6\\u09c7\\u09b6\\u09c7 \\u09b8\\u0995\\u09b2 \\u0995\\u09be\\u099c \\u09a4\\u09c7\\u09be \\u09ad\\u09c7\\u09be\\u099f\\u09be\\u09b0 \\u0986\\u0987\\u09a1\\u09bf \\u09a6\\u09bf\\u09df\\u09be \\u099a\\u09b2\\u09c7. \\u09b9\\u09be\\u09df\\u09b0\\u09c7 \\u09b8\\u09c7\\u09be\\u09a8\\u09be\\u09b0 \\u09ac\\u09be\\u0982\\u09b2\\u09be !!\",\n          \"\\u09ad\\u09be\\u09b0\\u09a4 \\u0985\\u09a4\\u09cd\\u09af\\u09a8\\u09cd\\u09a4 \\u099a\\u09be\\u09b2\\u09be\\u0995\\u09bf\\u09b0 \\u09b8\\u09be\\u09a5\\u09c7 \\u0986\\u09ae\\u09be\\u09a6\\u09c7\\u09b0 \\u09b8\\u09be\\u09a5\\u09c7 \\u09b8\\u09c1'\\u09b8\\u09ae\\u09aa\\u09b0\\u09cd\\u0995 \\u09a6\\u09c7\\u0996\\u09be\\u09df, \\u09ae\\u09c1\\u09b2\\u09a4 \\u09a4\\u09be\\u09b0\\u09be \\u09a8\\u09bf\\u099c\\u09a6\\u09c7\\u09b0 \\u09b8\\u09cd\\u09ac\\u09be\\u09b0\\u09cd\\u09a5 \\u099b\\u09c7\\u09dc\\u09c7 \\u09a6\\u09bf\\u09df\\u09c7 \\u0986\\u09ae\\u09be\\u09a6\\u09c7\\u09b0 \\u0985\\u09a7\\u09bf\\u0995\\u09be\\u09b0 \\u0986\\u09a6\\u09be\\u09df\\u09c7 \\u09b8\\u09c1\\u09af\\u09cb\\u0997 \\u0995\\u09b0\\u09c7 \\u09a6\\u09bf\\u09ac\\u09c7 \\u098f\\u09ae\\u09a8 \\u099a\\u09bf\\u09a8\\u09cd\\u09a4\\u09be \\u09a8\\u09be \\u0995\\u09b0\\u09be\\u0987 \\u0989\\u0993\\u09ae\\u0964\",\n          \"\\u09ac\\u09c1\\u099d\\u09a4\\u09c7 \\u09aa\\u09be\\u09b0\\u09be\\u09b0 \\u099c\\u09a8\\u09cd\\u09af \\u0986\\u09aa\\u09a8\\u09be\\u0995\\u09c7 \\u0985\\u09ad\\u09bf\\u09a8\\u09a8\\u09cd\\u09a6\\u09a8 \\u0964\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Emotion_label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1,\n          0,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cleaned\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11260,\n        \"samples\": [\n          \"\\u09ad\\u09be\\u0987\\u0986\\u09ae\\u09be\\u09b0 \\u099c\\u09be\\u09a8\\u09be\\u09ae\\u09a4\\u09c7 \\u09ac\\u09be\\u0982\\u09b2\\u09be\\u09a6\\u09c7\\u09b6\\u09c7\\u09b0 \\u0986\\u0987\\u09a8\\u09be\\u09a8\\u09c1\\u09af\\u09be\\u09df\\u09c0 \\u09aa\\u09cd\\u09b0\\u09c7\\u09b8\\u09bf\\u09a1\\u09c7\\u09a8\\u09cd\\u099f \\u0986\\u09b0 \\u09aa\\u09cd\\u09b0\\u09a7\\u09be\\u09a8 \\u09ac\\u09bf\\u099a\\u09be\\u09b0\\u09aa\\u09a4\\u09bf \\u099b\\u09be\\u09dc\\u09be \\u09ac\\u09be\\u0995\\u09bf \\u09b8\\u09ac\\u09be\\u09b0 \\u09ac\\u09bf\\u09b0\\u09c1\\u09a6\\u09cd\\u09a7\\u09c7 \\u09af\\u09c7 \\u0995\\u09c7\\u0989 \\u09ae\\u09be\\u09ae\\u09b2\\u09be \\u0995\\u09b0\\u09a4\\u09c7 \\u09aa\\u09be\\u09b0\\u09c7\\u09a8    \\u0986\\u0987\\u09a8 \\u09b0\\u0995\\u09cd\\u09b7\\u09be \\u0995\\u09be\\u09b0\\u09bf \\u09ac\\u09be\\u09b9\\u09bf\\u09a8\\u09c0 \\u0986\\u0987\\u09a8\\u09c7\\u09b0 \\u0986\\u0993\\u09a4\\u09be\\u09df \\u0986\\u09a8\\u09a4\\u09c7 \\u09aa\\u09be\\u09b0\\u09c7\\u09a8 \\u098f\\u0996\\u09be\\u09a8\\u09c7 \\u0986\\u0993\\u09df\\u09be\\u09ae\\u09c0\\u09b2\\u09c0\\u0997  \\u09ac\\u09bf\\u098f\\u09a8\\u09aa\\u09bf \\u0995\\u09c7\\u0989 \\u0986\\u0987\\u09a8\\u09c7\\u09b0 \\u0989\\u09b0\\u09cd\\u09a7\\u09c7 \\u09a8\\u09df \\u0995\\u09bf\\u09a8\\u09cd\\u09a4\\u09c1 \\u09a6\\u09c1\\u0983\\u0996\\u09c7\\u09b0 \\u0995\\u09a5\\u09be \\u09b9\\u09b2\\u09cb \\u0986\\u09ae\\u09be\\u09a6\\u09c7\\u09b0 \\u09a6\\u09c7\\u09b6\\u09c7 \\u0986\\u0987\\u09a8\\u09c7\\u09b0 \\u09ac\\u09cd\\u09af\\u09be\\u09ac\\u09b9\\u09be\\u09b0 \\u09a5\\u09c7\\u0995\\u09c7 \\u0985\\u09aa\\u09ac\\u09cd\\u09af\\u09be\\u09ac\\u09b9\\u09be\\u09b0\\u099f\\u09be\\u0987 \\u09ac\\u09c7\\u09b6\\u09bf \\u09b9\\u09df \\u09af\\u09c7\\u09ae\\u09a8 \\u0995\\u09bf\\u099b\\u09c1\\u09a6\\u09bf\\u09a8 \\u0986\\u0997\\u09c7\\u0993 \\u0997\\u09cb\\u09b2\\u09be\\u09ae\\u0986\\u099c\\u09ae \\u0995\\u09c7 \\u0995\\u09c7\\u09a8 \\u0997\\u09cd\\u09b0\\u09c7\\u09ab\\u09a4\\u09be\\u09b0 \\u0995\\u09b0\\u09be \\u09b9\\u099a\\u09cd\\u099b\\u09c7\\u09a8\\u09be \\u09a4\\u09be\\u09b0 \\u099c\\u09a8\\u09cd\\u09af \\u098f\\u0987 \\u0987\\u09ae\\u09b0\\u09be\\u09a8 \\u09b8\\u09b0\\u0995\\u09be\\u09b0 \\u09b8\\u09be\\u09b9\\u09c7\\u09ac\\u0987 \\u0995\\u09bf\\u09a8\\u09cd\\u09a4\\u09c1 \\u09b8\\u09b0\\u0995\\u09be\\u09b0 \\u0995\\u09c7 \\u09ac\\u09bf\\u09ad\\u09bf\\u09a8\\u09cd\\u09a8 \\u09b0\\u0995\\u09ae \\u0986\\u09b2\\u09cd\\u099f\\u09bf\\u09ae\\u09c7\\u099f\\u09be\\u09ae \\u09a6\\u09bf\\u09df\\u09c7\\u099b\\u09bf\\u09b2\\u09c7\\u09a8    \\u0986\\u099c \\u0989\\u09a8\\u09bf\\u0987 \\u098f\\u09b0 \\u09ac\\u09bf\\u09b0\\u09c1\\u09a6\\u09cd\\u09a7\\u09c7 \\u0995\\u09a5\\u09be \\u09ac\\u09b2\\u099b\\u09c7\\u09a8 \\u09b6\\u09ab\\u09bf\\u0995 \\u09b0\\u09c7\\u09b9\\u09ae\\u09be\\u09a8\\u09c7\\u09b0 \\u09aa\\u0995\\u09cd\\u09b7\\u09c7 \\u09b9\\u09df\\u09c7 \\u0985\\u09a5\\u099a \\u098f\\u0987 \\u09ac\\u09cd\\u09af\\u09be\\u0995\\u09cd\\u09a4\\u09bf\\u0987 \\u0995\\u09bf\\u09a8\\u09cd\\u09a4\\u09c1 \\u0995\\u09b0\\u09cd\\u09ae\\u099a\\u09be\\u09b0\\u09c0 \\u09a6\\u09c7\\u09b0 \\u09ac\\u09c7\\u09a4\\u09a8 \\u0986\\u09a4\\u09cd\\u09a4\\u09b8\\u09be\\u09a4 \\u0995\\u09b0\\u09c7 \\u09aa\\u09be\\u09b2\\u09bf\\u09df\\u09c7 \\u099c\\u09be\\u09ac\\u09be\\u09b0 \\u09b8\\u09ae\\u09df \\u09ac\\u09bf\\u09ae\\u09be\\u09a8 \\u09ac\\u09a8\\u09cd\\u09a6\\u09b0 \\u09a5\\u09c7\\u0995\\u09c7 \\u0997\\u09cd\\u09b0\\u09c7\\u09ab\\u09a4\\u09be\\u09b0 \\u09b9\\u09df\\u09c7\\u099b\\u09bf\\u09b2\\u09c7\\u09a8 \\u0986\\u09ae\\u09bf \\u099c\\u09be\\u09a8\\u09bf\\u09a8\\u09be \\u0986\\u09ae\\u09be\\u09b0 \\u098f\\u0987 \\u0995\\u09a5\\u09be \\u0997\\u09c1\\u09b2\\u09cb \\u0987\\u09ae\\u09b0\\u09be\\u09a8 \\u09b8\\u09be\\u09b9\\u09c7\\u09ac\\u09c7\\u09b0 \\u09a8\\u099c\\u09b0\\u09c7 \\u0986\\u09b8\\u09ac\\u09c7 \\u0995\\u09bf\\u09a8\\u09be    \\u09af\\u09a6\\u09bf \\u0986\\u09b8\\u09c7 \\u09a4\\u09ac\\u09c7 \\u0989\\u09a4\\u09cd\\u09a4\\u09b0\\u099f\\u09be \\u09a6\\u09bf\\u09ac\\u09c7\\u09a8 \\u0986\\u09b8\\u09be \\u0995\\u09b0\\u09bf \",\n          \"\\u0986\\u09b8\\u09b2\\u09c7 \\u099c\\u09c7\\u09a4\\u09be\\u09b0 \\u09ae\\u09a4 \\u09ae\\u09a8\\u09ae\\u09be\\u09a8\\u09b8\\u09bf\\u0995\\u09be \\u09ac\\u09b2\\u09a4\\u09c7 \\u0995\\u09bf\\u099b\\u09c1 \\u09a8\\u09c7\\u0987 \",\n          \"\\u0986\\u09ae\\u09b0\\u09be \\u09b8\\u09ac\\u09be\\u0987 \\u09a6\\u09cb\\u09df\\u09be \\u0995\\u09b0\\u09bf \\u0986\\u09b2\\u09cd\\u09b2\\u09be\\u09b9 \\u09af\\u09c7\\u09a8 \\u0986\\u09aa\\u09a8\\u09be\\u09a6\\u09c7\\u09b0 \\u09b8\\u09ac\\u09be\\u0987\\u0995\\u09c7 \\u098f\\u09b0\\u0995\\u09ae\\u0987 \\u09b9\\u09be\\u09b8\\u09bf \\u0996\\u09c1\\u09b6\\u09bf \\u09b0\\u09be\\u0996\\u09c7 \\u0986\\u09ae\\u09bf\\u09a8\\u09cd\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"filtered_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11034,\n        \"samples\": [\n          \"\\u09af\\u09be\\u0987\\u09df\\u09be \\u09ac\\u09be\\u09b2 \\u09ab\\u09be\\u09b2\\u09be\\u0987\\u09b8\\u09bf \\u09ac\\u09be\\u09b2 \\u09b9\\u09c1\\u09a6\\u09be\\u0987\",\n          \"\\u09aa\\u09be\\u0995\\u09bf\\u09b8\\u09cd\\u09a4\\u09be\\u09a8\\u09c7\\u09b0 \\u0995\\u09cd\\u09b7\\u09ae\\u09a4\\u09be\\u099a\\u09cd\\u09af\\u09c1\\u09a4 \\u09aa\\u09cd\\u09b0\\u09a7\\u09be\\u09a8\\u09ae\\u09a8\\u09cd\\u09a4\\u09cd\\u09b0\\u09c0 \\u09a8\\u0993\\u09df\\u09be\\u099c \\u09b6\\u09b0\\u09bf\\u09ab \\u09b6\\u09c7\\u0996 \\u09ae\\u09c1\\u099c\\u09bf\\u09ac\\u09c1\\u09b0 \\u09b0\\u09b9\\u09ae\\u09be\\u09a8 \\u09ac\\u09bf\\u09a6\\u09cd\\u09b0\\u09cb\\u09b9\\u09c0 \\u09a8\\u09be \\u09aa\\u09a5\\u09c7 \\u09ac\\u09be\\u09a7\\u09cd\\u09af \\u09e7\\u09ef\\u09ed\\u09e6 \\u09b8\\u09be\\u09b2\\u09c7\\u09b0 \\u09a8\\u09bf\\u09b0\\u09cd\\u09ac\\u09be\\u099a\\u09a8\\u09c7 \\u09ac\\u09bf\\u099c\\u09df\\u09c0 \\u09b9\\u0993\\u09df\\u09be\\u09b0 \\u09aa\\u09b0\\u0993 \\u09ac\\u0999\\u09cd\\u0997\\u09ac\\u09a8\\u09cd\\u09a7\\u09c1 \\u09b6\\u09c7\\u0996 \\u09ae\\u09c1\\u099c\\u09bf\\u09ac\\u09c1\\u09b0 \\u09b0\\u09b9\\u09ae\\u09be\\u09a8\\u09c7\\u09b0 \\u09b9\\u09be\\u09a4\\u09c7 \\u0995\\u09cd\\u09b7\\u09ae\\u09a4\\u09be \\u09b9\\u09b8\\u09cd\\u09a4\\u09be\\u09a8\\u09cd\\u09a4\\u09b0 \\u09a8\\u09be \\u09aa\\u09be\\u0995\\u09bf\\u09b8\\u09cd\\u09a4\\u09be\\u09a8\\u09bf \\u09a8\\u09c0\\u09a4\\u09bf\\u09b0 \\u09b8\\u09ae\\u09be\\u09b2\\u09cb\\u099a\\u09a8\\u09be \\u0995\\u09a5\\u09be \\u09a8\\u0993\\u09df\\u09be\\u099c \\u09ac\\u09be\\u0982\\u09b2\\u09be\\u09a6\\u09c7\\u09b6\\u09c7\\u09b0 \\u09aa\\u09be\\u0993\\u09a8\\u09be \\u09ab\\u09bf\\u09b0\\u09bf\\u09df\\u09c7\",\n          \"\\u09aa\\u09be\\u099e\\u09cd\\u099c\\u09be\\u09ac\\u09c0 \\u09ac\\u09be\\u09ac\\u09be\\u09b0\\u09c7\\u0993\\u0993 \\u09b0\\u09bf\\u09ae\\u09be\\u09a8\\u09cd\\u09a1\\u09c7 \\u09a8\\u09bf\\u09df\\u09be \\u09b6\\u09ab\\u09bf\\u0995 \\u09b0\\u09c7\\u09b9\\u09ae\\u09be\\u09a8\\u09c7\\u09b0 \\u09a1\\u09bf\\u09ae\\u09c7\\u09b0 \\u09ad\\u09be\\u0997 \\u09a6\\u09c7\\u09df\\u09be\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install --upgrade tensorflow torch transformers\n",
        "!pip install tqdm\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kg0Z5B-i5boT",
        "outputId": "74a3aec4-018f-4424-bc16-22c5efa5e1f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.3.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm  # Import tqdm for progress bar\n",
        "\n",
        "# Load dataset\n",
        "data = df\n",
        "\n",
        "# Ensure balanced dataset with up to 100 samples per emotion\n",
        "data = data.groupby('Emotion').apply(lambda x: x.sample(n=min(len(x), 6000), random_state=42)).reset_index(drop=True)\n",
        "\n",
        "# Split the dataset into features and labels\n",
        "X = data['filtered_text']\n",
        "y = data['Emotion']\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load BanglaBERT tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/banglabert\")\n",
        "model = AutoModel.from_pretrained(\"csebuetnlp/banglabert\")\n",
        "\n",
        "# Function to generate embeddings using BanglaBERT\n",
        "def generate_embeddings(texts):\n",
        "    embeddings = []\n",
        "    for text in tqdm(texts, desc=\"Generating embeddings\", ncols=100):  # Add progress bar\n",
        "        encoded_input = tokenizer(text, padding=True, truncation=True, return_tensors='pt', max_length=256)\n",
        "        with torch.no_grad():\n",
        "            model_output = model(**encoded_input)\n",
        "        embedding = model_output[\"last_hidden_state\"].mean(dim=1).numpy()  # Mean pooling\n",
        "        embeddings.append(embedding)\n",
        "    return np.vstack(embeddings)\n",
        "\n",
        "# Generate embeddings for training and test sets\n",
        "print(\"Generating embeddings for training set...\")\n",
        "X_train_embeddings = generate_embeddings(X_train.tolist())\n",
        "\n",
        "print(\"Generating embeddings for test set...\")\n",
        "X_test_embeddings = generate_embeddings(X_test.tolist())\n",
        "\n",
        "# Train a Random Forest classifier with progress bar\n",
        "print(\"Training Random Forest classifier...\")\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train_embeddings, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test_embeddings)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "mKK4DWIjijo5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e9760b0-f677-4783-a23a-414f80ef2093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-006efa0f15ce>:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  data = data.groupby('Emotion').apply(lambda x: x.sample(n=min(len(x), 6000), random_state=42)).reset_index(drop=True)\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating embeddings for training set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating embeddings: 100%|██████████████████████████████████| 28800/28800 [52:37<00:00,  9.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating embeddings for test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating embeddings: 100%|████████████████████████████████████| 7200/7200 [13:08<00:00,  9.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Random Forest classifier...\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.85      0.84      1220\n",
            "           1       0.92      0.87      0.89      1180\n",
            "           2       0.95      0.91      0.93      1199\n",
            "           3       0.85      0.82      0.83      1177\n",
            "           4       0.71      0.78      0.75      1183\n",
            "           5       0.90      0.91      0.90      1241\n",
            "\n",
            "    accuracy                           0.86      7200\n",
            "   macro avg       0.86      0.86      0.86      7200\n",
            "weighted avg       0.86      0.86      0.86      7200\n",
            "\n",
            "Accuracy: 0.8566666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, GRU, Bidirectional\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Define the extended BiLSTM+GRU model\n",
        "def create_bilstm_gru_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Bidirectional(LSTM(128, return_sequences=True, activation='tanh'), input_shape=input_shape),\n",
        "        Dropout(0.3),\n",
        "        Bidirectional(LSTM(64, return_sequences=True, activation='tanh')),\n",
        "        Dropout(0.3),\n",
        "        Bidirectional(GRU(128, return_sequences=True, activation='tanh')),\n",
        "        Dropout(0.3),\n",
        "        Bidirectional(GRU(64, return_sequences=False, activation='tanh')),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.4),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Prepare data for BiLSTM+GRU\n",
        "X_train_bilstm_gru = np.expand_dims(X_train_embeddings, axis=1)\n",
        "X_test_bilstm_gru = np.expand_dims(X_test_embeddings, axis=1)\n",
        "\n",
        "# Define the input shape and number of classes\n",
        "input_shape = X_train_bilstm_gru.shape[1:]\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "# Create and train the extended BiLSTM+GRU model\n",
        "bilstm_gru_model = create_bilstm_gru_model(input_shape, num_classes)\n",
        "bilstm_gru_model.summary()\n",
        "\n",
        "print(\"Training BiLSTM+GRU model...\")\n",
        "bilstm_gru_model.fit(X_train_bilstm_gru, y_train, epochs=100, batch_size=40, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the BiLSTM+GRU model\n",
        "print(\"Evaluating BiLSTM+GRU model...\")\n",
        "y_pred_bilstm_gru = np.argmax(bilstm_gru_model.predict(X_test_bilstm_gru), axis=1)\n",
        "\n",
        "# Display evaluation results\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_bilstm_gru))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_bilstm_gru))\n"
      ],
      "metadata": {
        "id": "qGqeHo_awsTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN"
      ],
      "metadata": {
        "id": "kH48htXspcsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Define the CNN model\n",
        "def create_cnn_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv1D(128, kernel_size=5, activation='relu', input_shape=input_shape),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.3),\n",
        "        Conv1D(64, kernel_size=5, activation='relu'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.3),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.4),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Prepare data for CNN\n",
        "X_train_cnn = np.expand_dims(X_train_embeddings, axis=-1)\n",
        "X_test_cnn = np.expand_dims(X_test_embeddings, axis=-1)\n",
        "\n",
        "# Define the input shape and number of classes\n",
        "input_shape = X_train_cnn.shape[1:]\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "# Create and train the CNN model\n",
        "cnn_model = create_cnn_model(input_shape, num_classes)\n",
        "cnn_model.summary()\n",
        "\n",
        "print(\"Training CNN model...\")\n",
        "cnn_model.fit(X_train_cnn, y_train, epochs=10, batch_size=60, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the CNN model\n",
        "print(\"Evaluating CNN model...\")\n",
        "y_pred_cnn = np.argmax(cnn_model.predict(X_test_cnn), axis=1)\n",
        "\n",
        "# Display evaluation results\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_cnn))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_cnn))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aOX2ZjDTkYn6",
        "outputId": "764450be-5234-4520-e720-e6c4756b4aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m764\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m768\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m382\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m382\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m378\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m41,024\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m189\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m189\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12096\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m1,548,416\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m774\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">764</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">382</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">382</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">378</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">41,024</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">189</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">189</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12096</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,548,416</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,590,982\u001b[0m (6.07 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,590,982</span> (6.07 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,590,982\u001b[0m (6.07 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,590,982</span> (6.07 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training CNN model...\n",
            "Epoch 1/10\n",
            "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 380ms/step - accuracy: 0.1980 - loss: 1.7823 - val_accuracy: 0.2887 - val_loss: 1.6920\n",
            "Epoch 2/10\n",
            "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 284ms/step - accuracy: 0.2916 - loss: 1.6872 - val_accuracy: 0.3450 - val_loss: 1.6121\n",
            "Epoch 3/10\n",
            "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 288ms/step - accuracy: 0.3375 - loss: 1.6118 - val_accuracy: 0.4054 - val_loss: 1.5279\n",
            "Epoch 4/10\n",
            "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 291ms/step - accuracy: 0.3734 - loss: 1.5499 - val_accuracy: 0.4441 - val_loss: 1.4655\n",
            "Epoch 5/10\n",
            "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 320ms/step - accuracy: 0.4002 - loss: 1.4858 - val_accuracy: 0.4708 - val_loss: 1.3862\n",
            "Epoch 6/10\n",
            "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 292ms/step - accuracy: 0.4352 - loss: 1.4240 - val_accuracy: 0.5087 - val_loss: 1.3472\n",
            "Epoch 7/10\n",
            "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 292ms/step - accuracy: 0.4551 - loss: 1.3823 - val_accuracy: 0.5241 - val_loss: 1.3016\n",
            "Epoch 8/10\n",
            "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 302ms/step - accuracy: 0.4601 - loss: 1.3500 - val_accuracy: 0.5530 - val_loss: 1.2411\n",
            "Epoch 9/10\n",
            "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 295ms/step - accuracy: 0.4847 - loss: 1.3056 - val_accuracy: 0.5568 - val_loss: 1.2114\n",
            "Epoch 10/10\n",
            "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 303ms/step - accuracy: 0.4919 - loss: 1.2880 - val_accuracy: 0.5774 - val_loss: 1.1720\n",
            "Evaluating CNN model...\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.55      0.54      1220\n",
            "           1       0.63      0.65      0.64      1180\n",
            "           2       0.56      0.75      0.64      1199\n",
            "           3       0.60      0.63      0.61      1177\n",
            "           4       0.44      0.24      0.31      1183\n",
            "           5       0.65      0.65      0.65      1241\n",
            "\n",
            "    accuracy                           0.58      7200\n",
            "   macro avg       0.57      0.58      0.57      7200\n",
            "weighted avg       0.57      0.58      0.57      7200\n",
            "\n",
            "Accuracy: 0.5779166666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BILSTM"
      ],
      "metadata": {
        "id": "UId_6VBBpWn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Define the BiLSTM model\n",
        "def create_bilstm_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Bidirectional(LSTM(128, return_sequences=True, activation='tanh'), input_shape=input_shape),\n",
        "        Dropout(0.3),\n",
        "        Bidirectional(LSTM(64, activation='tanh')),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.4),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Prepare data for BiLSTM\n",
        "X_train_bilstm = np.expand_dims(X_train_embeddings, axis=1)\n",
        "X_test_bilstm = np.expand_dims(X_test_embeddings, axis=1)\n",
        "\n",
        "# Define the input shape and number of classes\n",
        "input_shape = X_train_bilstm.shape[1:]\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "# Create and train the BiLSTM model\n",
        "bilstm_model = create_bilstm_model(input_shape, num_classes)\n",
        "bilstm_model.summary()\n",
        "\n",
        "print(\"Training BiLSTM model...\")\n",
        "bilstm_model.fit(X_train_bilstm, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the BiLSTM model\n",
        "print(\"Evaluating BiLSTM model...\")\n",
        "y_pred_bilstm = np.argmax(bilstm_model.predict(X_test_bilstm), axis=1)\n",
        "\n",
        "# Display evaluation results\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_bilstm))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_bilstm))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BiW-3xHOpU25",
        "outputId": "81e1ad32-dd90-4f0f-c417-bf1b7a354c03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │         \u001b[38;5;34m918,528\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m164,352\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m774\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">918,528</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,100,166\u001b[0m (4.20 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,100,166</span> (4.20 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,100,166\u001b[0m (4.20 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,100,166</span> (4.20 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training BiLSTM model...\n",
            "Epoch 1/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 21ms/step - accuracy: 0.2333 - loss: 1.7434 - val_accuracy: 0.3415 - val_loss: 1.5930\n",
            "Epoch 2/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.3463 - loss: 1.5929 - val_accuracy: 0.3950 - val_loss: 1.5127\n",
            "Epoch 3/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.4050 - loss: 1.5010 - val_accuracy: 0.4148 - val_loss: 1.4543\n",
            "Epoch 4/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.4582 - loss: 1.3904 - val_accuracy: 0.5071 - val_loss: 1.3146\n",
            "Epoch 5/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.5133 - loss: 1.2720 - val_accuracy: 0.5309 - val_loss: 1.2471\n",
            "Epoch 6/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - accuracy: 0.5646 - loss: 1.1649 - val_accuracy: 0.5762 - val_loss: 1.1381\n",
            "Epoch 7/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.6037 - loss: 1.0738 - val_accuracy: 0.6130 - val_loss: 1.0645\n",
            "Epoch 8/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.6396 - loss: 0.9851 - val_accuracy: 0.6161 - val_loss: 1.0719\n",
            "Epoch 9/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.6631 - loss: 0.9278 - val_accuracy: 0.6413 - val_loss: 0.9959\n",
            "Epoch 10/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.6889 - loss: 0.8647 - val_accuracy: 0.6736 - val_loss: 0.9273\n",
            "Epoch 11/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.7134 - loss: 0.7962 - val_accuracy: 0.6925 - val_loss: 0.8789\n",
            "Epoch 12/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - accuracy: 0.7381 - loss: 0.7449 - val_accuracy: 0.7087 - val_loss: 0.8401\n",
            "Epoch 13/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.7533 - loss: 0.7080 - val_accuracy: 0.7215 - val_loss: 0.8235\n",
            "Epoch 14/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.7517 - loss: 0.6898 - val_accuracy: 0.7403 - val_loss: 0.7887\n",
            "Epoch 15/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.7747 - loss: 0.6418 - val_accuracy: 0.7481 - val_loss: 0.7662\n",
            "Epoch 16/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.7893 - loss: 0.6010 - val_accuracy: 0.7519 - val_loss: 0.7655\n",
            "Epoch 17/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.7966 - loss: 0.5885 - val_accuracy: 0.7608 - val_loss: 0.7575\n",
            "Epoch 18/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - accuracy: 0.8052 - loss: 0.5516 - val_accuracy: 0.7710 - val_loss: 0.7339\n",
            "Epoch 19/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.8169 - loss: 0.5210 - val_accuracy: 0.7788 - val_loss: 0.7136\n",
            "Epoch 20/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - accuracy: 0.8207 - loss: 0.5041 - val_accuracy: 0.7769 - val_loss: 0.7234\n",
            "Evaluating BiLSTM model...\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.67      0.75      1220\n",
            "           1       0.76      0.86      0.81      1180\n",
            "           2       0.84      0.86      0.85      1199\n",
            "           3       0.80      0.80      0.80      1177\n",
            "           4       0.61      0.61      0.61      1183\n",
            "           5       0.80      0.86      0.83      1241\n",
            "\n",
            "    accuracy                           0.78      7200\n",
            "   macro avg       0.78      0.78      0.78      7200\n",
            "weighted avg       0.78      0.78      0.78      7200\n",
            "\n",
            "Accuracy: 0.7769444444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GRU"
      ],
      "metadata": {
        "id": "XLop4l8spiYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, GRU, Bidirectional\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Define the BiGRU model\n",
        "def create_bigru_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Bidirectional(GRU(128, return_sequences=True, activation='tanh'), input_shape=input_shape),\n",
        "        Dropout(0.3),\n",
        "        Bidirectional(GRU(64, activation='tanh')),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.4),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Prepare data for BiGRU\n",
        "X_train_bigru = np.expand_dims(X_train_embeddings, axis=1)\n",
        "X_test_bigru = np.expand_dims(X_test_embeddings, axis=1)\n",
        "\n",
        "# Define the input shape and number of classes\n",
        "input_shape = X_train_bigru.shape[1:]\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "# Create and train the BiGRU model\n",
        "bigru_model = create_bigru_model(input_shape, num_classes)\n",
        "bigru_model.summary()\n",
        "\n",
        "print(\"Training BiGRU model...\")\n",
        "bigru_model.fit(X_train_bigru, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the BiGRU model\n",
        "print(\"Evaluating BiGRU model...\")\n",
        "y_pred_bigru = np.argmax(bigru_model.predict(X_test_bigru), axis=1)\n",
        "\n",
        "# Display evaluation results\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_bigru))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_bigru))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9iGleKJ-phft",
        "outputId": "51ec8c27-bce1-422a-b90d-062196defa84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │         \u001b[38;5;34m689,664\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m123,648\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m774\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">689,664</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">123,648</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m830,598\u001b[0m (3.17 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">830,598</span> (3.17 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m830,598\u001b[0m (3.17 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">830,598</span> (3.17 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training BiGRU model...\n",
            "Epoch 1/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.2162 - loss: 1.7647 - val_accuracy: 0.3257 - val_loss: 1.6200\n",
            "Epoch 2/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.3345 - loss: 1.6160 - val_accuracy: 0.3825 - val_loss: 1.5163\n",
            "Epoch 3/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.3763 - loss: 1.5430 - val_accuracy: 0.4224 - val_loss: 1.4588\n",
            "Epoch 4/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.4285 - loss: 1.4488 - val_accuracy: 0.4536 - val_loss: 1.3998\n",
            "Epoch 5/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.4705 - loss: 1.3487 - val_accuracy: 0.4878 - val_loss: 1.3182\n",
            "Epoch 6/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.5195 - loss: 1.2625 - val_accuracy: 0.5188 - val_loss: 1.2543\n",
            "Epoch 7/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.5571 - loss: 1.1693 - val_accuracy: 0.5507 - val_loss: 1.2103\n",
            "Epoch 8/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.5964 - loss: 1.0875 - val_accuracy: 0.5918 - val_loss: 1.0813\n",
            "Epoch 9/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - accuracy: 0.6211 - loss: 1.0182 - val_accuracy: 0.6226 - val_loss: 1.0195\n",
            "Epoch 10/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.6504 - loss: 0.9624 - val_accuracy: 0.6523 - val_loss: 0.9755\n",
            "Epoch 11/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.6816 - loss: 0.8834 - val_accuracy: 0.6731 - val_loss: 0.9308\n",
            "Epoch 12/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.6927 - loss: 0.8472 - val_accuracy: 0.6809 - val_loss: 0.9089\n",
            "Epoch 13/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.7125 - loss: 0.7957 - val_accuracy: 0.6845 - val_loss: 0.8958\n",
            "Epoch 14/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.7259 - loss: 0.7619 - val_accuracy: 0.6998 - val_loss: 0.8700\n",
            "Epoch 15/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - accuracy: 0.7383 - loss: 0.7290 - val_accuracy: 0.7161 - val_loss: 0.8534\n",
            "Epoch 16/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.7599 - loss: 0.6739 - val_accuracy: 0.7306 - val_loss: 0.8174\n",
            "Epoch 17/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.7701 - loss: 0.6506 - val_accuracy: 0.7411 - val_loss: 0.7740\n",
            "Epoch 18/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.7766 - loss: 0.6274 - val_accuracy: 0.7458 - val_loss: 0.7683\n",
            "Epoch 19/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.7899 - loss: 0.5985 - val_accuracy: 0.7521 - val_loss: 0.7617\n",
            "Epoch 20/20\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.7881 - loss: 0.5911 - val_accuracy: 0.7615 - val_loss: 0.7599\n",
            "Evaluating BiGRU model...\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.75      0.72      1220\n",
            "           1       0.70      0.83      0.76      1180\n",
            "           2       0.84      0.86      0.85      1199\n",
            "           3       0.82      0.80      0.81      1177\n",
            "           4       0.66      0.49      0.56      1183\n",
            "           5       0.83      0.83      0.83      1241\n",
            "\n",
            "    accuracy                           0.76      7200\n",
            "   macro avg       0.76      0.76      0.76      7200\n",
            "weighted avg       0.76      0.76      0.76      7200\n",
            "\n",
            "Accuracy: 0.7601388888888889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BILSTM+GRU"
      ],
      "metadata": {
        "id": "qUzR7h9uvkEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, GRU, Bidirectional\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Define the BiLSTM+GRU model\n",
        "def create_bilstm_gru_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Bidirectional(LSTM(128, return_sequences=True, activation='tanh'), input_shape=input_shape),\n",
        "        Dropout(0.3),\n",
        "        Bidirectional(GRU(64, return_sequences=False, activation='tanh')),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.4),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Prepare data for BiLSTM+GRU\n",
        "X_train_bilstm_gru = np.expand_dims(X_train_embeddings, axis=1)\n",
        "X_test_bilstm_gru = np.expand_dims(X_test_embeddings, axis=1)\n",
        "\n",
        "# Define the input shape and number of classes\n",
        "input_shape = X_train_bilstm_gru.shape[1:]\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "# Create and train the BiLSTM+GRU model\n",
        "bilstm_gru_model = create_bilstm_gru_model(input_shape, num_classes)\n",
        "bilstm_gru_model.summary()\n",
        "\n",
        "print(\"Training BiLSTM+GRU model...\")\n",
        "bilstm_gru_model.fit(X_train_bilstm_gru, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the BiLSTM+GRU model\n",
        "print(\"Evaluating BiLSTM+GRU model...\")\n",
        "y_pred_bilstm_gru = np.argmax(bilstm_gru_model.predict(X_test_bilstm_gru), axis=1)\n",
        "\n",
        "# Display evaluation results\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_bilstm_gru))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_bilstm_gru))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "72E_rMs1voY_",
        "outputId": "d4629af6-71c8-4f2f-98c7-18100c557704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │         \u001b[38;5;34m918,528\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_5 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m123,648\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m774\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">918,528</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">123,648</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,059,462\u001b[0m (4.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,059,462</span> (4.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,059,462\u001b[0m (4.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,059,462</span> (4.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training BiLSTM+GRU model...\n",
            "Epoch 1/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.2260 - loss: 1.7502 - val_accuracy: 0.3012 - val_loss: 1.6718\n",
            "Epoch 2/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.3438 - loss: 1.6014 - val_accuracy: 0.3724 - val_loss: 1.5331\n",
            "Epoch 3/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.3874 - loss: 1.5183 - val_accuracy: 0.4363 - val_loss: 1.4381\n",
            "Epoch 4/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.4472 - loss: 1.4128 - val_accuracy: 0.4920 - val_loss: 1.3344\n",
            "Epoch 5/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.5078 - loss: 1.2867 - val_accuracy: 0.5293 - val_loss: 1.2520\n",
            "Epoch 6/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.5601 - loss: 1.1711 - val_accuracy: 0.5875 - val_loss: 1.1281\n",
            "Epoch 7/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.6045 - loss: 1.0724 - val_accuracy: 0.6003 - val_loss: 1.0948\n",
            "Epoch 8/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.6400 - loss: 0.9873 - val_accuracy: 0.6300 - val_loss: 1.0405\n",
            "Epoch 9/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.6652 - loss: 0.9284 - val_accuracy: 0.6510 - val_loss: 0.9916\n",
            "Epoch 10/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.6930 - loss: 0.8611 - val_accuracy: 0.6644 - val_loss: 0.9655\n",
            "Epoch 11/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.7095 - loss: 0.8093 - val_accuracy: 0.7153 - val_loss: 0.8448\n",
            "Epoch 12/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.7284 - loss: 0.7579 - val_accuracy: 0.7161 - val_loss: 0.8370\n",
            "Epoch 13/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.7480 - loss: 0.7142 - val_accuracy: 0.7233 - val_loss: 0.8377\n",
            "Epoch 14/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - accuracy: 0.7617 - loss: 0.6733 - val_accuracy: 0.7302 - val_loss: 0.8197\n",
            "Epoch 15/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.7753 - loss: 0.6392 - val_accuracy: 0.7536 - val_loss: 0.7605\n",
            "Epoch 16/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.7815 - loss: 0.6205 - val_accuracy: 0.7540 - val_loss: 0.7671\n",
            "Epoch 17/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.7989 - loss: 0.5781 - val_accuracy: 0.7675 - val_loss: 0.7461\n",
            "Epoch 18/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.8033 - loss: 0.5605 - val_accuracy: 0.7717 - val_loss: 0.7474\n",
            "Epoch 19/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - accuracy: 0.8135 - loss: 0.5356 - val_accuracy: 0.7828 - val_loss: 0.7109\n",
            "Epoch 20/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.8257 - loss: 0.5036 - val_accuracy: 0.7832 - val_loss: 0.7111\n",
            "Epoch 21/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.8284 - loss: 0.4836 - val_accuracy: 0.7872 - val_loss: 0.7163\n",
            "Epoch 22/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.8351 - loss: 0.4665 - val_accuracy: 0.7981 - val_loss: 0.6957\n",
            "Epoch 23/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.8442 - loss: 0.4407 - val_accuracy: 0.8021 - val_loss: 0.6778\n",
            "Epoch 24/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.8508 - loss: 0.4267 - val_accuracy: 0.8014 - val_loss: 0.6882\n",
            "Epoch 25/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.8531 - loss: 0.4095 - val_accuracy: 0.7906 - val_loss: 0.7201\n",
            "Epoch 26/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.8606 - loss: 0.3928 - val_accuracy: 0.7892 - val_loss: 0.7365\n",
            "Epoch 27/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.8637 - loss: 0.3890 - val_accuracy: 0.8092 - val_loss: 0.7094\n",
            "Epoch 28/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.8701 - loss: 0.3694 - val_accuracy: 0.8071 - val_loss: 0.7371\n",
            "Epoch 29/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.8716 - loss: 0.3642 - val_accuracy: 0.8097 - val_loss: 0.6948\n",
            "Epoch 30/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.8732 - loss: 0.3573 - val_accuracy: 0.8090 - val_loss: 0.6990\n",
            "Epoch 31/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.8758 - loss: 0.3442 - val_accuracy: 0.8182 - val_loss: 0.7224\n",
            "Epoch 32/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 37ms/step - accuracy: 0.8809 - loss: 0.3336 - val_accuracy: 0.8217 - val_loss: 0.7026\n",
            "Epoch 33/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 19ms/step - accuracy: 0.8838 - loss: 0.3287 - val_accuracy: 0.8193 - val_loss: 0.7240\n",
            "Epoch 34/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.8909 - loss: 0.3021 - val_accuracy: 0.8278 - val_loss: 0.7110\n",
            "Epoch 35/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.8924 - loss: 0.3015 - val_accuracy: 0.8196 - val_loss: 0.7185\n",
            "Epoch 36/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.8907 - loss: 0.2966 - val_accuracy: 0.8297 - val_loss: 0.7373\n",
            "Epoch 37/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.8929 - loss: 0.2980 - val_accuracy: 0.8314 - val_loss: 0.7441\n",
            "Epoch 38/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.8993 - loss: 0.2857 - val_accuracy: 0.8321 - val_loss: 0.7368\n",
            "Epoch 39/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9020 - loss: 0.2764 - val_accuracy: 0.8229 - val_loss: 0.7975\n",
            "Epoch 40/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.8995 - loss: 0.2729 - val_accuracy: 0.8295 - val_loss: 0.7570\n",
            "Epoch 41/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.9045 - loss: 0.2701 - val_accuracy: 0.8333 - val_loss: 0.7596\n",
            "Epoch 42/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9050 - loss: 0.2617 - val_accuracy: 0.8366 - val_loss: 0.7346\n",
            "Epoch 43/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9045 - loss: 0.2602 - val_accuracy: 0.8306 - val_loss: 0.7563\n",
            "Epoch 44/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - accuracy: 0.9069 - loss: 0.2558 - val_accuracy: 0.8316 - val_loss: 0.7643\n",
            "Epoch 45/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9140 - loss: 0.2380 - val_accuracy: 0.8333 - val_loss: 0.7596\n",
            "Epoch 46/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9091 - loss: 0.2493 - val_accuracy: 0.8267 - val_loss: 0.7838\n",
            "Epoch 47/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.9106 - loss: 0.2363 - val_accuracy: 0.8398 - val_loss: 0.7647\n",
            "Epoch 48/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.9135 - loss: 0.2334 - val_accuracy: 0.8297 - val_loss: 0.7689\n",
            "Epoch 49/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.9169 - loss: 0.2271 - val_accuracy: 0.8345 - val_loss: 0.7746\n",
            "Epoch 50/50\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.9151 - loss: 0.2286 - val_accuracy: 0.8332 - val_loss: 0.8086\n",
            "Evaluating BiLSTM+GRU model...\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.80      0.80      1220\n",
            "           1       0.82      0.88      0.85      1180\n",
            "           2       0.85      0.91      0.88      1199\n",
            "           3       0.90      0.79      0.84      1177\n",
            "           4       0.74      0.71      0.73      1183\n",
            "           5       0.87      0.88      0.88      1241\n",
            "\n",
            "    accuracy                           0.83      7200\n",
            "   macro avg       0.83      0.83      0.83      7200\n",
            "weighted avg       0.83      0.83      0.83      7200\n",
            "\n",
            "Accuracy: 0.8294444444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#double bilstm+gru"
      ],
      "metadata": {
        "id": "QhwWcso322X3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, GRU, Bidirectional\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Define the extended BiLSTM+GRU model\n",
        "def create_bilstm_gru_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Bidirectional(LSTM(128, return_sequences=True, activation='tanh'), input_shape=input_shape),\n",
        "        Dropout(0.3),\n",
        "        Bidirectional(LSTM(64, return_sequences=True, activation='tanh')),\n",
        "        Dropout(0.3),\n",
        "        Bidirectional(GRU(128, return_sequences=True, activation='tanh')),\n",
        "        Dropout(0.3),\n",
        "        Bidirectional(GRU(64, return_sequences=False, activation='tanh')),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.4),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Prepare data for BiLSTM+GRU\n",
        "X_train_bilstm_gru = np.expand_dims(X_train_embeddings, axis=1)\n",
        "X_test_bilstm_gru = np.expand_dims(X_test_embeddings, axis=1)\n",
        "\n",
        "# Define the input shape and number of classes\n",
        "input_shape = X_train_bilstm_gru.shape[1:]\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "# Create and train the extended BiLSTM+GRU model\n",
        "bilstm_gru_model = create_bilstm_gru_model(input_shape, num_classes)\n",
        "bilstm_gru_model.summary()\n",
        "\n",
        "print(\"Training BiLSTM+GRU model...\")\n",
        "bilstm_gru_model.fit(X_train_bilstm_gru, y_train, epochs=100, batch_size=40, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the BiLSTM+GRU model\n",
        "print(\"Evaluating BiLSTM+GRU model...\")\n",
        "y_pred_bilstm_gru = np.argmax(bilstm_gru_model.predict(X_test_bilstm_gru), axis=1)\n",
        "\n",
        "# Display evaluation results\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_bilstm_gru))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_bilstm_gru))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8J5KlsLY2625",
        "outputId": "02680dae-b0f5-4754-eb0f-d98912fe6d90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional_6 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │         \u001b[38;5;34m918,528\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_7 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │         \u001b[38;5;34m164,352\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_8 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │         \u001b[38;5;34m198,144\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_9 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m123,648\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m774\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">918,528</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">198,144</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">123,648</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,421,958\u001b[0m (5.42 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,421,958</span> (5.42 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,421,958\u001b[0m (5.42 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,421,958</span> (5.42 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training BiLSTM+GRU model...\n",
            "Epoch 1/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 37ms/step - accuracy: 0.2202 - loss: 1.7570 - val_accuracy: 0.3016 - val_loss: 1.6333\n",
            "Epoch 2/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.3235 - loss: 1.6219 - val_accuracy: 0.3733 - val_loss: 1.5560\n",
            "Epoch 3/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - accuracy: 0.3759 - loss: 1.5446 - val_accuracy: 0.4076 - val_loss: 1.4809\n",
            "Epoch 4/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 33ms/step - accuracy: 0.4257 - loss: 1.4588 - val_accuracy: 0.4587 - val_loss: 1.4008\n",
            "Epoch 5/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - accuracy: 0.4844 - loss: 1.3541 - val_accuracy: 0.5010 - val_loss: 1.3041\n",
            "Epoch 6/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 32ms/step - accuracy: 0.5306 - loss: 1.2471 - val_accuracy: 0.5316 - val_loss: 1.2248\n",
            "Epoch 7/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 34ms/step - accuracy: 0.5680 - loss: 1.1568 - val_accuracy: 0.5800 - val_loss: 1.1329\n",
            "Epoch 8/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - accuracy: 0.6006 - loss: 1.0748 - val_accuracy: 0.5887 - val_loss: 1.1180\n",
            "Epoch 9/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.6379 - loss: 0.9935 - val_accuracy: 0.6286 - val_loss: 1.0123\n",
            "Epoch 10/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 34ms/step - accuracy: 0.6577 - loss: 0.9383 - val_accuracy: 0.6568 - val_loss: 0.9576\n",
            "Epoch 11/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - accuracy: 0.6785 - loss: 0.8870 - val_accuracy: 0.6759 - val_loss: 0.9303\n",
            "Epoch 12/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.7004 - loss: 0.8290 - val_accuracy: 0.6898 - val_loss: 0.8984\n",
            "Epoch 13/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.7142 - loss: 0.7964 - val_accuracy: 0.6826 - val_loss: 0.9133\n",
            "Epoch 14/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 30ms/step - accuracy: 0.7355 - loss: 0.7475 - val_accuracy: 0.7080 - val_loss: 0.8547\n",
            "Epoch 15/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - accuracy: 0.7379 - loss: 0.7375 - val_accuracy: 0.7151 - val_loss: 0.8352\n",
            "Epoch 16/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.7585 - loss: 0.6821 - val_accuracy: 0.7358 - val_loss: 0.8154\n",
            "Epoch 17/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 35ms/step - accuracy: 0.7695 - loss: 0.6512 - val_accuracy: 0.7507 - val_loss: 0.7747\n",
            "Epoch 18/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.7737 - loss: 0.6327 - val_accuracy: 0.7497 - val_loss: 0.7714\n",
            "Epoch 19/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.7861 - loss: 0.6033 - val_accuracy: 0.7679 - val_loss: 0.7380\n",
            "Epoch 20/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.7956 - loss: 0.5761 - val_accuracy: 0.7599 - val_loss: 0.7487\n",
            "Epoch 21/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.8028 - loss: 0.5586 - val_accuracy: 0.7802 - val_loss: 0.7139\n",
            "Epoch 22/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 33ms/step - accuracy: 0.8139 - loss: 0.5320 - val_accuracy: 0.7760 - val_loss: 0.7174\n",
            "Epoch 23/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - accuracy: 0.8254 - loss: 0.5004 - val_accuracy: 0.7911 - val_loss: 0.6851\n",
            "Epoch 24/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.8246 - loss: 0.5040 - val_accuracy: 0.7712 - val_loss: 0.7021\n",
            "Epoch 25/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.8367 - loss: 0.4714 - val_accuracy: 0.7799 - val_loss: 0.7142\n",
            "Epoch 26/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.8443 - loss: 0.4532 - val_accuracy: 0.7906 - val_loss: 0.7065\n",
            "Epoch 27/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.8443 - loss: 0.4546 - val_accuracy: 0.7953 - val_loss: 0.7060\n",
            "Epoch 28/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.8489 - loss: 0.4396 - val_accuracy: 0.7960 - val_loss: 0.6773\n",
            "Epoch 29/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 34ms/step - accuracy: 0.8514 - loss: 0.4301 - val_accuracy: 0.8023 - val_loss: 0.6783\n",
            "Epoch 30/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.8579 - loss: 0.4154 - val_accuracy: 0.8069 - val_loss: 0.6558\n",
            "Epoch 31/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.8505 - loss: 0.4253 - val_accuracy: 0.8016 - val_loss: 0.6706\n",
            "Epoch 32/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 34ms/step - accuracy: 0.8672 - loss: 0.3922 - val_accuracy: 0.8038 - val_loss: 0.6819\n",
            "Epoch 33/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.8678 - loss: 0.3823 - val_accuracy: 0.8158 - val_loss: 0.6631\n",
            "Epoch 34/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.8642 - loss: 0.3796 - val_accuracy: 0.8155 - val_loss: 0.6594\n",
            "Epoch 35/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 35ms/step - accuracy: 0.8771 - loss: 0.3542 - val_accuracy: 0.8158 - val_loss: 0.6665\n",
            "Epoch 36/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.8815 - loss: 0.3516 - val_accuracy: 0.8146 - val_loss: 0.6868\n",
            "Epoch 37/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.8848 - loss: 0.3338 - val_accuracy: 0.8220 - val_loss: 0.6863\n",
            "Epoch 38/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 33ms/step - accuracy: 0.8846 - loss: 0.3383 - val_accuracy: 0.8234 - val_loss: 0.6796\n",
            "Epoch 39/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.8788 - loss: 0.3452 - val_accuracy: 0.8212 - val_loss: 0.6759\n",
            "Epoch 40/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.8809 - loss: 0.3374 - val_accuracy: 0.8267 - val_loss: 0.7063\n",
            "Epoch 41/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - accuracy: 0.8844 - loss: 0.3251 - val_accuracy: 0.8217 - val_loss: 0.6583\n",
            "Epoch 42/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.8901 - loss: 0.3130 - val_accuracy: 0.8231 - val_loss: 0.7064\n",
            "Epoch 43/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - accuracy: 0.8932 - loss: 0.3075 - val_accuracy: 0.8255 - val_loss: 0.6625\n",
            "Epoch 44/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - accuracy: 0.8926 - loss: 0.3035 - val_accuracy: 0.8255 - val_loss: 0.6709\n",
            "Epoch 45/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - accuracy: 0.8980 - loss: 0.2900 - val_accuracy: 0.8260 - val_loss: 0.7030\n",
            "Epoch 46/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.8945 - loss: 0.2972 - val_accuracy: 0.8321 - val_loss: 0.7093\n",
            "Epoch 47/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 34ms/step - accuracy: 0.9049 - loss: 0.2780 - val_accuracy: 0.8274 - val_loss: 0.6639\n",
            "Epoch 48/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - accuracy: 0.9052 - loss: 0.2707 - val_accuracy: 0.8271 - val_loss: 0.7215\n",
            "Epoch 49/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.9053 - loss: 0.2734 - val_accuracy: 0.8342 - val_loss: 0.7037\n",
            "Epoch 50/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 35ms/step - accuracy: 0.9039 - loss: 0.2754 - val_accuracy: 0.8316 - val_loss: 0.6710\n",
            "Epoch 51/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.9036 - loss: 0.2690 - val_accuracy: 0.8290 - val_loss: 0.7113\n",
            "Epoch 52/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.9092 - loss: 0.2641 - val_accuracy: 0.8302 - val_loss: 0.7009\n",
            "Epoch 53/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - accuracy: 0.9108 - loss: 0.2546 - val_accuracy: 0.8285 - val_loss: 0.7175\n",
            "Epoch 54/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - accuracy: 0.9095 - loss: 0.2570 - val_accuracy: 0.8333 - val_loss: 0.7176\n",
            "Epoch 55/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 33ms/step - accuracy: 0.9132 - loss: 0.2550 - val_accuracy: 0.8281 - val_loss: 0.7320\n",
            "Epoch 56/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - accuracy: 0.9156 - loss: 0.2436 - val_accuracy: 0.8326 - val_loss: 0.7426\n",
            "Epoch 57/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 34ms/step - accuracy: 0.9115 - loss: 0.2440 - val_accuracy: 0.8207 - val_loss: 0.7152\n",
            "Epoch 58/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - accuracy: 0.9094 - loss: 0.2497 - val_accuracy: 0.8217 - val_loss: 0.7609\n",
            "Epoch 59/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - accuracy: 0.9144 - loss: 0.2375 - val_accuracy: 0.8375 - val_loss: 0.6916\n",
            "Epoch 60/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.9182 - loss: 0.2266 - val_accuracy: 0.8349 - val_loss: 0.7037\n",
            "Epoch 61/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.9189 - loss: 0.2320 - val_accuracy: 0.8344 - val_loss: 0.7271\n",
            "Epoch 62/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 34ms/step - accuracy: 0.9196 - loss: 0.2220 - val_accuracy: 0.8302 - val_loss: 0.7841\n",
            "Epoch 63/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.9209 - loss: 0.2188 - val_accuracy: 0.8368 - val_loss: 0.7227\n",
            "Epoch 64/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 33ms/step - accuracy: 0.9238 - loss: 0.2134 - val_accuracy: 0.8290 - val_loss: 0.7629\n",
            "Epoch 65/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - accuracy: 0.9208 - loss: 0.2169 - val_accuracy: 0.8330 - val_loss: 0.7535\n",
            "Epoch 66/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 33ms/step - accuracy: 0.9164 - loss: 0.2402 - val_accuracy: 0.8323 - val_loss: 0.7398\n",
            "Epoch 67/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.9215 - loss: 0.2178 - val_accuracy: 0.8372 - val_loss: 0.7310\n",
            "Epoch 68/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.9202 - loss: 0.2154 - val_accuracy: 0.8359 - val_loss: 0.8013\n",
            "Epoch 69/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 33ms/step - accuracy: 0.9223 - loss: 0.2094 - val_accuracy: 0.8309 - val_loss: 0.8019\n",
            "Epoch 70/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.9240 - loss: 0.2093 - val_accuracy: 0.8450 - val_loss: 0.7580\n",
            "Epoch 71/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.9198 - loss: 0.2231 - val_accuracy: 0.8352 - val_loss: 0.7538\n",
            "Epoch 72/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 34ms/step - accuracy: 0.9260 - loss: 0.2093 - val_accuracy: 0.8368 - val_loss: 0.7274\n",
            "Epoch 73/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - accuracy: 0.9244 - loss: 0.2088 - val_accuracy: 0.8380 - val_loss: 0.7456\n",
            "Epoch 74/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 35ms/step - accuracy: 0.9242 - loss: 0.2080 - val_accuracy: 0.8370 - val_loss: 0.7737\n",
            "Epoch 75/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.9288 - loss: 0.2018 - val_accuracy: 0.8403 - val_loss: 0.8286\n",
            "Epoch 76/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - accuracy: 0.9276 - loss: 0.1970 - val_accuracy: 0.8387 - val_loss: 0.7403\n",
            "Epoch 77/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.9300 - loss: 0.1928 - val_accuracy: 0.8405 - val_loss: 0.7991\n",
            "Epoch 78/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - accuracy: 0.9290 - loss: 0.1924 - val_accuracy: 0.8365 - val_loss: 0.7714\n",
            "Epoch 79/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 32ms/step - accuracy: 0.9278 - loss: 0.1964 - val_accuracy: 0.8405 - val_loss: 0.7601\n",
            "Epoch 80/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.9257 - loss: 0.1967 - val_accuracy: 0.8372 - val_loss: 0.7794\n",
            "Epoch 81/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - accuracy: 0.9326 - loss: 0.1833 - val_accuracy: 0.8385 - val_loss: 0.7707\n",
            "Epoch 82/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.9264 - loss: 0.1913 - val_accuracy: 0.8401 - val_loss: 0.7356\n",
            "Epoch 83/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 35ms/step - accuracy: 0.9282 - loss: 0.1889 - val_accuracy: 0.8377 - val_loss: 0.7667\n",
            "Epoch 84/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.9289 - loss: 0.1964 - val_accuracy: 0.8349 - val_loss: 0.8214\n",
            "Epoch 85/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 33ms/step - accuracy: 0.9330 - loss: 0.1756 - val_accuracy: 0.8391 - val_loss: 0.7951\n",
            "Epoch 86/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 33ms/step - accuracy: 0.9336 - loss: 0.1737 - val_accuracy: 0.8405 - val_loss: 0.8308\n",
            "Epoch 87/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 32ms/step - accuracy: 0.9311 - loss: 0.1898 - val_accuracy: 0.8408 - val_loss: 0.7528\n",
            "Epoch 88/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.9324 - loss: 0.1856 - val_accuracy: 0.8398 - val_loss: 0.7629\n",
            "Epoch 89/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 34ms/step - accuracy: 0.9355 - loss: 0.1673 - val_accuracy: 0.8373 - val_loss: 0.8082\n",
            "Epoch 90/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 32ms/step - accuracy: 0.9318 - loss: 0.1850 - val_accuracy: 0.8439 - val_loss: 0.8197\n",
            "Epoch 91/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 32ms/step - accuracy: 0.9350 - loss: 0.1725 - val_accuracy: 0.8392 - val_loss: 0.8019\n",
            "Epoch 92/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 32ms/step - accuracy: 0.9364 - loss: 0.1710 - val_accuracy: 0.8351 - val_loss: 0.8684\n",
            "Epoch 93/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - accuracy: 0.9318 - loss: 0.1806 - val_accuracy: 0.8373 - val_loss: 0.8421\n",
            "Epoch 94/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - accuracy: 0.9349 - loss: 0.1706 - val_accuracy: 0.8385 - val_loss: 0.8216\n",
            "Epoch 95/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 32ms/step - accuracy: 0.9344 - loss: 0.1750 - val_accuracy: 0.8408 - val_loss: 0.8189\n",
            "Epoch 96/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 35ms/step - accuracy: 0.9315 - loss: 0.1727 - val_accuracy: 0.8349 - val_loss: 0.8040\n",
            "Epoch 97/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 32ms/step - accuracy: 0.9359 - loss: 0.1674 - val_accuracy: 0.8392 - val_loss: 0.8464\n",
            "Epoch 98/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 32ms/step - accuracy: 0.9337 - loss: 0.1685 - val_accuracy: 0.8417 - val_loss: 0.7216\n",
            "Epoch 99/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 32ms/step - accuracy: 0.9359 - loss: 0.1699 - val_accuracy: 0.8450 - val_loss: 0.8045\n",
            "Epoch 100/100\n",
            "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.9382 - loss: 0.1594 - val_accuracy: 0.8377 - val_loss: 0.7827\n",
            "Evaluating BiLSTM+GRU model...\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.82      0.82      1220\n",
            "           1       0.85      0.87      0.86      1180\n",
            "           2       0.87      0.91      0.89      1199\n",
            "           3       0.87      0.84      0.85      1177\n",
            "           4       0.78      0.69      0.73      1183\n",
            "           5       0.85      0.90      0.88      1241\n",
            "\n",
            "    accuracy                           0.84      7200\n",
            "   macro avg       0.84      0.84      0.84      7200\n",
            "weighted avg       0.84      0.84      0.84      7200\n",
            "\n",
            "Accuracy: 0.8416666666666667\n"
          ]
        }
      ]
    }
  ]
}